{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPaDBcxa9U7o8IYRIgW02hn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BOrtizL/Proyecto-7-DataScience/blob/main/4_1_1_UDD_Proyecto_M7_Modelo_de_RandomForest_ac_BarbaraOrtiz.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este notebook aplicarmos el modelo de RandomForest en la data de alta confianza para tener una coparación de su rendimiento."
      ],
      "metadata": {
        "id": "Ury-gKNvkQpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l10Q3umpkeTG",
        "outputId": "b6e1297c-556c-4fcb-9bc1-3b4123b95410"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.decomposition import PCA\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "fMvugJOdkP2Z"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cargar los datos de alta confianza transformados**"
      ],
      "metadata": {
        "id": "AETGOtjbkt8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ruta del archivo original en Google Drive\n",
        "ruta_archivo_drive = \"/content/drive/My Drive/Proyecto 7/raw/df_concatenado_alta_confianza.pkl\"\n",
        "\n",
        "# Cargar el DataFrame desde el archivo\n",
        "with open(ruta_archivo_drive, 'rb') as f:\n",
        "    df_concatenado_alta_confianza = pickle.load(f)"
      ],
      "metadata": {
        "id": "v0NMnbMMkxQv"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 1: Separar las características y la etiqueta\n",
        "X = df_concatenado_alta_confianza.drop('gender', axis=1)\n",
        "y = df_concatenado_alta_confianza['gender']\n",
        "\n",
        "# Paso 2: Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Y5jphCOqkz6Q"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 3: Preprocesamiento - Escalado de características\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "# Paso 4: Aplicar PCA en el conjunto de entrenamiento\n",
        "pca = PCA(n_components=7)  # Número óptimo de componentes\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)"
      ],
      "metadata": {
        "id": "ZUI3kcBwk8BJ"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xHIscarx27H",
        "outputId": "6f91c4ce-25c1-4f14-b636-078b6e98f77c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.67      0.80         3\n",
            "           2       0.67      1.00      0.80         2\n",
            "\n",
            "    accuracy                           0.80         5\n",
            "   macro avg       0.83      0.83      0.80         5\n",
            "weighted avg       0.87      0.80      0.80         5\n",
            "\n",
            "[[2 1]\n",
            " [0 2]]\n"
          ]
        }
      ],
      "source": [
        "# Paso 5: Crear y entrenar el modelo RandomForest\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_train_pca, y_train)\n",
        "\n",
        "# Paso 6: Predecir en el conjunto de prueba\n",
        "y_pred = rf_model.predict(X_test_pca)\n",
        "\n",
        "# Paso 7: Evaluar el modelo\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Calcular la matriz de confusión\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(conf_matrix)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observación:**\n",
        "El modelo tiene un 80% de precisión, lo que significa que está funcionando correctamente.\n",
        "\n",
        "A continuación la interpretación de las métricas de clasificación:\n",
        "- Precision: Para la Clase 1, el modelo tiene una precisión del 100%, lo que significa que de todas las predicciones que hizo para la Clase 1, el 100% fueron correctas. Para la Clase 2, la precisión es del 67%, lo que indica que el 67% de las predicciones para la Clase 2 fueron correctas.\n",
        "\n",
        "- Recall: La Clase 1 tiene un valor de recall del 67%, lo que significa que el 67% de las muestras de la Clase 1 fueron identificadas correctamente. Para la Clase 2, el recall es del 100%, lo que indica que todas las muestras de la Clase 2 fueron identificadas correctamente.\n",
        "\n",
        "- F1-score: Es la media armónica entre precisión y recall.\n",
        "Para ambas clases, el F1-score es del 80%.\n",
        "\n",
        "- Accuracy: La precisión global del modelo es del 80%, es decir, el 80% de las muestras fueron clasificadas correctamente.\n",
        "\n",
        "- Matriz de Confusión:\n",
        "El modelo clasificó correctamente 2 muestras de la Clase 1 y 2 muestras de la Clase 2.\n",
        "Falló en clasificar 1 muestra de la Clase 1.\n",
        "\n"
      ],
      "metadata": {
        "id": "Iet55-A3sDub"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusión:**"
      ],
      "metadata": {
        "id": "n1tVBhNBvnPX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora que tenemos el resultado de desempeño de ambos modelos, es el modelo de Regresión Logistica quien tiene un excelente performance y es el modelo que se sugiere avanzar en este proyecto."
      ],
      "metadata": {
        "id": "ByWNZlhQvsYt"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dPOTNoh9sFOf"
      },
      "execution_count": 78,
      "outputs": []
    }
  ]
}