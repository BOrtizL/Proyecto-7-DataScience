{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPHuWZywhzqXIOnH9bU/N8p"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["En este notebook aplicarmos el modelo de RandomForest en la data transformada para tener una coparación de su rendimiento."],"metadata":{"id":"Ury-gKNvkQpE"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l10Q3umpkeTG","executionInfo":{"status":"ok","timestamp":1719085367583,"user_tz":240,"elapsed":25230,"user":{"displayName":"Barbara Ortiz","userId":"12183043448921656595"}},"outputId":"32204d03-a945-4ebb-fffa-e8c37fb228ca"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import pickle\n","import pandas as pd\n","import numpy as np\n","\n","from sklearn.model_selection import GridSearchCV, train_test_split, StratifiedKFold, cross_validate\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.decomposition import PCA\n","from sklearn.ensemble import RandomForestClassifier\n","import matplotlib.pyplot as plt\n"],"metadata":{"id":"fMvugJOdkP2Z","executionInfo":{"status":"ok","timestamp":1719085370301,"user_tz":240,"elapsed":2719,"user":{"displayName":"Barbara Ortiz","userId":"12183043448921656595"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["**Cargar los datos transformados**"],"metadata":{"id":"AETGOtjbkt8q"}},{"cell_type":"code","source":["# Ruta del archivo original en Google Drive\n","ruta_archivo_drive = \"/content/drive/My Drive/Proyecto 7/data/df_concatenado.pkl\"\n","\n","# Cargar el DataFrame desde el archivo\n","with open(ruta_archivo_drive, 'rb') as f:\n","    df_concatenado = pickle.load(f)"],"metadata":{"id":"v0NMnbMMkxQv","executionInfo":{"status":"ok","timestamp":1719085370301,"user_tz":240,"elapsed":2,"user":{"displayName":"Barbara Ortiz","userId":"12183043448921656595"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Paso 1: Separar las características y la etiqueta\n","X = df_concatenado.drop('gender', axis=1)\n","y = df_concatenado['gender']\n","\n","# Paso 2: Dividir los datos en conjuntos de entrenamiento y prueba\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"],"metadata":{"id":"Y5jphCOqkz6Q","executionInfo":{"status":"ok","timestamp":1719085370776,"user_tz":240,"elapsed":476,"user":{"displayName":"Barbara Ortiz","userId":"12183043448921656595"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Paso 3: Preprocesamiento - Escalado de características\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","\n","# Paso 4: Aplicar PCA en el conjunto de entrenamiento\n","pca = PCA(n_components=8)  # Número óptimo de componentes\n","X_train_pca = pca.fit_transform(X_train_scaled)\n","X_test_pca = pca.transform(X_test_scaled)"],"metadata":{"id":"ZUI3kcBwk8BJ","executionInfo":{"status":"ok","timestamp":1719085370776,"user_tz":240,"elapsed":2,"user":{"displayName":"Barbara Ortiz","userId":"12183043448921656595"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9xHIscarx27H","executionInfo":{"status":"ok","timestamp":1719085577531,"user_tz":240,"elapsed":206757,"user":{"displayName":"Barbara Ortiz","userId":"12183043448921656595"}},"outputId":"e300568d-3adf-4ad3-9aed-25c27b2e2367"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mejores hiperparámetros encontrados mediante GridSearchCV:\n","{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}\n","\n","Reporte de clasificación en el conjunto de prueba:\n","              precision    recall  f1-score   support\n","\n","           1       1.00      0.97      0.98        59\n","           2       0.94      1.00      0.97        29\n","\n","    accuracy                           0.98        88\n","   macro avg       0.97      0.98      0.97        88\n","weighted avg       0.98      0.98      0.98        88\n","\n","\n","Matriz de confusión en el conjunto de prueba:\n","[[57  2]\n"," [ 0 29]]\n"]}],"source":["# Paso 5: Definir el modelo base de RandomForestClassifier con max_features='sqrt'\n","rf_model = RandomForestClassifier(max_features='sqrt', random_state=42)\n","\n","# Paso 6: Definir el grid de hiperparámetros\n","param_grid = {\n","    'n_estimators': [100, 200, 300],\n","    'max_depth': [None, 10, 20, 30],\n","    'min_samples_split': [2, 5, 10],\n","    'min_samples_leaf': [1, 2, 4]\n","}\n","\n","# Paso 7: Configurar GridSearchCV\n","grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='accuracy')\n","\n","# Paso 8: Ejecutar la búsqueda de hiperparámetros\n","grid_search.fit(X_train, y_train)\n","\n","# Paso 9: Obtener el mejor modelo y los mejores hiperparámetros\n","best_model = grid_search.best_estimator_\n","best_params = grid_search.best_params_\n","\n","print(\"Mejores hiperparámetros encontrados mediante GridSearchCV:\")\n","print(best_params)\n","\n","# Paso 10: Predecir en el conjunto de prueba utilizando el mejor modelo encontrado por GridSearchCV\n","y_pred = best_model.predict(X_test)\n","\n","# Mostrar métricas de evaluación en el conjunto de prueba\n","print(\"\\nReporte de clasificación en el conjunto de prueba:\")\n","print(classification_report(y_test, y_pred))\n","\n","# Calcular la matriz de confusión en el conjunto de prueba\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","print(\"\\nMatriz de confusión en el conjunto de prueba:\")\n","print(conf_matrix)"]},{"cell_type":"markdown","source":["**Observación:**\n","- Mejores hiperparámetros encontrados mediante GridSearchCV:\n","{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}\n","Estos hiperparámetros indican que el modelo de RandomForestClassifier entrenado tiene una profundidad máxima indefinida (max_depth=None), un mínimo de muestras por hoja de 1 (min_samples_leaf=1), un mínimo de muestras requeridas para dividir un nodo interno de 10 (min_samples_split=10), y utiliza 200 estimadores en el bosque (n_estimators=200).\n","\n","**Reporte de clasificación en el conjunto de prueba:**\n"," - Precisión (precision): Es la proporción de identificaciones positivas correctas (verdaderos positivos) respecto a todas las identificaciones positivas (verdaderos positivos + falsos positivos). Para la clase 1, la precisión es del 100%, lo que indica que todos los casos predichos como clase 1 fueron realmente de clase 1. Para la clase 2, la precisión es del 94%, lo que indica que el 6% de los casos predichos como clase 2 fueron falsos positivos.\n","\n"," - Recall: Es la proporción de identificaciones positivas correctas (verdaderos positivos) respecto a todas las instancias que realmente son de esa clase (verdaderos positivos + falsos negativos). Para ambas clases, el recall es alto (97% y 100% respectivamente), indicando que el modelo identifica la mayoría de las instancias positivas de manera efectiva.\n","\n"," - F1-score: Es una media armónica entre precisión y recall. Es útil cuando las clases están desbalanceadas, como parece ser el caso aquí. Tanto para la clase 1 como para la clase 2, el f1-score es alto (98% y 97% respectivamente), lo que sugiere un buen equilibrio entre precisión y recall.\n","\n"," - Exactitud (accuracy): Es la proporción de predicciones correctas respecto al total de predicciones. En este caso, la exactitud es del 98%, lo que significa que el modelo clasifica correctamente el 98% de las instancias en el conjunto de prueba.\n","\n","**Matriz de confusión en el conjunto de prueba:**\n","La matriz de confusión muestra en la diagonal principal los verdaderos positivos (TP) y verdaderos negativos (TN), mientras que fuera de la diagonal muestra los falsos positivos (FP) y falsos negativos (FN). En este caso:\n","Para la clase 1 (primera fila), el modelo predijo correctamente 57 instancias como clase 1 (TP) y 2 instancias como falsos positivos (FP).\n","Para la clase 2 (segunda fila), el modelo predijo correctamente 29 instancias como clase 2 (TP) y ninguna como falsos negativos (FN).\n","\n","**Estos resultados indican que el modelo entrenado tiene un buen desempeño en la clasificación de ambos grupos (clase 1 y clase 2), con una alta precisión y recall, así como una exactitud general del 98%.**\n","\n","\n","\n","\n","\n"],"metadata":{"id":"I836d66OlUN_"}},{"cell_type":"code","source":["# Configurar la validación cruzada k-fold estratificada\n","cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","# Definir los scorers\n","scoring = {\n","    'accuracy': 'accuracy',\n","    'precision': 'precision_weighted',\n","    'recall': 'recall_weighted',\n","    'f1': 'f1_weighted'\n","}\n","\n","# Realizar la validación cruzada\n","cv_results = cross_validate(best_model, X_train_pca, y_train, cv=cv, scoring=scoring, return_train_score=True)\n","\n","# Mostrar los resultados de la validación cruzada\n","print(\"\\nResultados de la validación cruzada:\")\n","for metric_name in cv_results.keys():\n","    average_score = np.mean(cv_results[metric_name])\n","    std_dev = np.std(cv_results[metric_name])\n","    print(f\"{metric_name}: {average_score:.4f} ± {std_dev:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X1zalVR5M0t6","executionInfo":{"status":"ok","timestamp":1719085579508,"user_tz":240,"elapsed":1980,"user":{"displayName":"Barbara Ortiz","userId":"12183043448921656595"}},"outputId":"37c075ec-8b77-4d4f-aafc-8d17f74a18ec"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Resultados de la validación cruzada:\n","fit_time: 0.3462 ± 0.0131\n","score_time: 0.0172 ± 0.0014\n","test_accuracy: 0.9030 ± 0.0279\n","train_accuracy: 0.9815 ± 0.0069\n","test_precision: 0.9044 ± 0.0293\n","train_precision: 0.9818 ± 0.0068\n","test_recall: 0.9030 ± 0.0279\n","train_recall: 0.9815 ± 0.0069\n","test_f1: 0.9024 ± 0.0285\n","train_f1: 0.9815 ± 0.0069\n"]}]},{"cell_type":"markdown","source":["**Resultados de la validación cruzada:**\n"," - fit_time: Tiempo promedio de ajuste del modelo durante cada fold de validación cruzada. En promedio, cada ajuste tomó aproximadamente 0.3459 segundos, con una desviación estándar de 0.0120 segundos.\n","\n"," - score_time: Tiempo promedio de predicción del modelo durante cada fold de validación cruzada. En promedio, cada predicción tomó aproximadamente 0.0178 segundos, con una desviación estándar de 0.0020 segundos.\n","\n"," - test_accuracy: Precisión promedio en el conjunto de prueba durante cada fold de validación cruzada. El modelo logró una precisión promedio del 90.30%, con una desviación estándar de 0.0279, lo que indica una consistencia en la capacidad del modelo para generalizar sobre datos no vistos.\n","\n"," - train_accuracy: Precisión promedio en el conjunto de entrenamiento durante cada fold de validación cruzada. La precisión promedio en entrenamiento fue del 98.15%, con una desviación estándar de 0.0069. Esto sugiere que el modelo ajusta muy bien los datos de entrenamiento, pero con una ligera variabilidad entre los folds.\n","\n"," - test_precision: Precisión promedio en el conjunto de prueba para la métrica de precisión. La precisión promedio en prueba fue del 90.44%, con una desviación estándar de 0.0293.\n","\n"," - train_precision: Precisión promedio en el conjunto de entrenamiento para la métrica de precisión. La precisión promedio en entrenamiento fue del 98.18%, con una desviación estándar de 0.0068.\n","\n"," - test_recall: Recall promedio en el conjunto de prueba. El recall promedio en prueba fue del 90.30%, con una desviación estándar de 0.0279.\n","\n"," - train_recall: Recall promedio en el conjunto de entrenamiento. El recall promedio en entrenamiento fue del 98.15%, con una desviación estándar de 0.0069.\n","\n"," - test_f1: Puntuación F1 promedio en el conjunto de prueba. La puntuación F1 promedio en prueba fue del 90.24%, con una desviación estándar de 0.0285.\n","\n"," - train_f1: Puntuación F1 promedio en el conjunto de entrenamiento. La puntuación F1 promedio en entrenamiento fue del 98.15%, con una desviación estándar de 0.0069.\n","\n","**Análisis:**\n"," - Precisión y Recall: Tanto en el conjunto de prueba como en el de entrenamiento, el modelo muestra resultados consistentes y altos en precisión y recall, lo cual es indicativo de un buen equilibrio entre la capacidad de predicción correcta y la capacidad de capturar correctamente las instancias positivas.\n","\n"," - Puntuación F1: La puntuación F1, que es una medida armónica de precisión y recall, también muestra un rendimiento sólido y consistente en ambos conjuntos, lo cual es deseable especialmente en problemas donde las clases están desbalanceadas.\n","\n"," - Tiempo de Ejecución: Los tiempos de ajuste y predicción son relativamente bajos, lo cual es positivo para la aplicabilidad del modelo en situaciones prácticas.\n","\n","**En resumen, los resultados indican que el modelo entrenado con los mejores hiperparámetros encontrados tiene un buen desempeño en la clasificación de los datos, mostrando consistencia tanto en las métricas de rendimiento como en los tiempos de ejecución durante la validación cruzada.**\n","\n","\n","\n","\n","\n"],"metadata":{"id":"eU38782qmQar"}},{"cell_type":"code","source":[],"metadata":{"id":"dPOTNoh9sFOf","executionInfo":{"status":"ok","timestamp":1719085579508,"user_tz":240,"elapsed":12,"user":{"displayName":"Barbara Ortiz","userId":"12183043448921656595"}}},"execution_count":7,"outputs":[]}]}